{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89be09d2",
   "metadata": {},
   "source": [
    "Predict Wine Quality Akshay\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb64310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w = pd.read_csv(\"winequality-white.csv\", delimiter = \";\")\n",
    "df_r = pd.read_csv(\"winequality-red.csv\", delimiter = \";\")\n",
    "\n",
    "#Drop duplicates \n",
    "df_w.drop_duplicates(inplace=True)\n",
    "df_r.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0871a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a categorical column to determine the wine type\n",
    "df_w['Type'] = \"W\"\n",
    "df_r[\"Type\"] = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(df_w.columns.values)\n",
    "#Concat both dataframes\n",
    "df = pd.concat([df_w, df_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867f5da",
   "metadata": {},
   "source": [
    "Data Exploratory Analysis\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac93e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = wine.corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm',\\\n",
    "            center=0, annot_kws={'size': 6, 'fontweight': 'bold', 'rotation': 45})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0c681",
   "metadata": {},
   "source": [
    "Heatmap Observations\n",
    "--------------------------------\n",
    "1. Strong negative correlation between alcohol and density\n",
    "2. Free and total sulfur dioxide are strongly positively correlated\n",
    "3. White wines have more sulfur dioxide which makes sense as white wines are more prone to oxidation and as sulfur dioxide is used as a form of preservative in wines, there would be a greater presence of them in white wines\n",
    "4. Red wines have higher volatile acidity due to longer fermenation which leads to higher volatile acid presence \n",
    "5. Generally as alcohol content increases, density of wine decreases. The key factor that contributes to the relationship between density and alcohol content is the presence of ethanol (alcohol) in the wine. During the fermentation process, yeast converts sugar in the grape juice into alcohol and carbon dioxide. The alcohol produced is lighter than water, so it reduces the overall density of the wine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d950af",
   "metadata": {},
   "source": [
    "Boxplots\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = wine.drop(['Type', 'quality'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdbc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the desired order for the \"quality\" column (assuming it's a numerical column)\n",
    "quality_order = sorted(wine['quality'].unique(), reverse=True)\n",
    "\n",
    "# Calculate the number of rows and columns for the subplots\n",
    "num_rows = (len(columns_to_plot) + 1) // 2  # Round up to the nearest integer for number of rows\n",
    "num_cols = min(len(columns_to_plot), 2)  # Maximum of 2 columns per row\n",
    "\n",
    "# Create a figure with multiple rows and two columns per row\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 4*num_rows), sharey=False)\n",
    "\n",
    "# Plot horizontal violin plots for 'quality' column against each column in columns_to_plot\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    ax = sns.boxplot(x=column, y='quality', data=wine, ax=axes[row, col], orient='h', order=quality_order, palette='PuBu')\n",
    "    ax.set_title(f'Quality vs. {column}')\n",
    "    if col == 0:\n",
    "        ax.set_ylabel('Quality')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for i in range(len(columns_to_plot), num_rows * num_cols):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles and y-labels\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd19381",
   "metadata": {},
   "source": [
    "Histograms\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f227249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import skew function to measure skewness\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6196d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skew function to interpret the skew score\n",
    "def interpret_skewness(skew_value):\n",
    "    if skew_value < -1:\n",
    "        return \"Highly negatively skewed (left-skewed)\"\n",
    "    elif -1 <= skew_value < -0.5:\n",
    "        return \"Moderately negatively skewed\"\n",
    "    elif -0.5 <= skew_value < -0.1:\n",
    "        return \"Slightly negatively skewed\"\n",
    "    elif -0.1 <= skew_value <= 0.1:\n",
    "        return \"Approximately symmetric distribution\"\n",
    "    elif 0.1 <= skew_value < 0.5:\n",
    "        return \"Slightly positively skewed\"\n",
    "    elif 0.5 <= skew_value < 1:\n",
    "        return \"Moderately positively skewed\"\n",
    "    else:\n",
    "        return \"Highly positively skewed (right-skewed)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1545bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for types of wine\n",
    "mask_w = wine['Type'] == \"W\"\n",
    "mask_r = wine['Type'] == \"R\"\n",
    "\n",
    "# Get the list of columns in the DataFrame (excluding the 'Type' column)\n",
    "columns_to_plot = wine.drop(['Type', 'quality'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae286e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple rows and three columns per row\n",
    "num_rows = len(columns_to_plot)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, 4*num_rows))\n",
    "\n",
    "# Plot histograms for each column for white and red wines and overall histograms\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    sns.histplot(wine[mask_w][column], ax=axes[i, 0], color=\"#87CEEB\", bins=10, label='White Wine')\n",
    "    sns.histplot(wine[mask_r][column], ax=axes[i, 1], color=\"#90EE90\", bins=10, label='Red Wine')\n",
    "    sns.histplot(wine[column], ax=axes[i, 2], color=\"#FFC0CB\", bins=10)\n",
    "\n",
    "    axes[i, 0].set_title(f'{column} - White Wine')\n",
    "    axes[i, 1].set_title(f'{column} - Red Wine')\n",
    "    axes[i, 2].set_title(f'{column} - Overall')\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print skewness for each column for white and red wines\n",
    "for column in columns_to_plot:\n",
    "    #Calculate the skewness of each graph/column broken up by Wine Type and Overall\n",
    "    skew_white = skew(wine[mask_w][column])\n",
    "    skew_red = skew(wine[mask_r][column])\n",
    "    skew_overall = skew(wine[column])\n",
    "    \n",
    "    #Interpret the Skew number\n",
    "    skew_white_interpretation = interpret_skewness(skew_white)\n",
    "    skew_red_interpretation = interpret_skewness(skew_red)\n",
    "    skew_overall_interpretation = interpret_skewness(skew_overall)\n",
    "    \n",
    "    #Print results\n",
    "    print(f\"Skewness of White Wine {column}: {round(skew_white, 2)} : {skew_white_interpretation}\")\n",
    "    print(f\"Skewness of Red Wine {column}: {round(skew_red, 2)} : {skew_red_interpretation}\")\n",
    "    print(f\"Skewness of Overall {column}: {round(skew_overall, 2)} : {skew_overall_interpretation}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5faf4de",
   "metadata": {},
   "source": [
    "Histogram and Skew Score Observations (Predictor Variables)\n",
    "----------------------------------------------------------------------------------------\n",
    "1. We dropped typeand quality because they are categorical variables and we are currently plotting quantitative variables by type and then overall. We will plot **quality** and **type** below\n",
    "2. Based on the graphs and skew scores above, most columns overall are all positively skewed from moderately to highly positively skewed \n",
    "3. In this context, this means that the **mean > median** but the degree to which varies \n",
    "4. **Skewness > 1** implies there are **extremely high outlier** that pull the histogram to the **left (right skewed)**\n",
    "5. Predictors that are **highly skewed**\n",
    "    - Fixed Acidity\n",
    "    - Volatile Acidity\n",
    "    - Residual Sugar\n",
    "    - Chlorides\n",
    "    - Free Sulfur Dioxide\n",
    "    - Sulphates\n",
    "6. Only **total sulfur dioxide (overall)** has approximately symmetric distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = wine.drop(wine.columns[[1,2,3,4,5,6,7,8,9,10,11]], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(5, 7))\n",
    "\n",
    "# Plot the first histogram on the first subplot\n",
    "sns.histplot(wine['Type'], ax=axes[0], color=\"#87CEEB\", bins=10)\n",
    "axes[0].set_title('Histogram - Type')\n",
    "\n",
    "# Plot the second histogram on the second subplot\n",
    "sns.histplot(wine['quality'], ax=axes[1], color=\"#90EE90\", bins=10)\n",
    "axes[1].set_title('Histogram - Quality')\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "\n",
    "#Print the distribution of Type and quality\n",
    "print(round(wine['Type'].value_counts()/len(wine),2))\n",
    "print(round(wine['quality'].value_counts()/len(wine),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf1b17",
   "metadata": {},
   "source": [
    "Histogram Observations (Response Variables)\n",
    "------------------------------------------------------------------\n",
    "1. 74% of total observations are of white wines\n",
    "2. 77% of total observations are rated of quality 5 or 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a00044",
   "metadata": {},
   "source": [
    "Based on our results, most of our columns are highly skewed and so we want to reduce skewness to have a more symmetric distribution, before we standardize our values\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b5dc8",
   "metadata": {},
   "source": [
    "We will now proceed to transform our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox, yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will test out 3 different transformations and determine which one is the best for each of the columns\n",
    "wine_skewed_df = wine[['fixed acidity', 'volatile acidity', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'sulphates']]\n",
    "\n",
    "none_list = []\n",
    "log_list = []\n",
    "boxcox_list = []\n",
    "yeoj_list = []\n",
    "# Loop through each column and perform transformations\n",
    "for column in wine_skewed_df.columns:\n",
    "    # Get the column data as a NumPy array\n",
    "    column_data = wine_skewed_df[column].values\n",
    "    #Apply skew score and interpret normally \n",
    "    skew_nom = skew(column_data)\n",
    "    no_skew = interpret_skewness(skew_nom)\n",
    "    \n",
    "    # Apply log transformation and calculate skewness\n",
    "    log_transformed_data = np.log(column_data)\n",
    "    skew_log = interpret_skewness(skew(log_transformed_data))\n",
    "    \n",
    "    # Apply Box-Cox transformation and calculate skewness\n",
    "    boxcox_transformed_data, lambda_boxcox = boxcox(column_data)\n",
    "    skew_boxcox = interpret_skewness(skew(boxcox_transformed_data))\n",
    "    \n",
    "    # Apply Yeo-Johnson transformation and calculate skewness\n",
    "    yeojohnson_transformed_data, lambda_yeo = yeojohnson(column_data)\n",
    "    skew_yeojohnson = interpret_skewness(skew(yeojohnson_transformed_data))\n",
    "    \n",
    "    none_list.append(no_skew)\n",
    "    log_list.append(skew_log)\n",
    "    boxcox_list.append(skew_boxcox)\n",
    "    yeoj_list.append(skew_yeojohnson)\n",
    "\n",
    "transform_dict = {\"Before Transformation\": none_list ,\"Log Transformation\" : log_list, \"BoxCox Transformation\" : boxcox_list, \"YeoJohnson Transformation\": yeoj_list}\n",
    "transform_df = pd.DataFrame(transform_dict, index = list(wine_skewed_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bdb9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166839b6",
   "metadata": {},
   "source": [
    "As we can see, for the highly positively skewed columns, BoxCox transformation works the best. So we will proceed with that and make the respective updates for the original wine dataframe and the new dataframe to plot histograms and visualize this change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in wine_skewed_df.columns:\n",
    "    # Get the column data as a NumPy array\n",
    "    column_data = wine_skewed_df[column].values\n",
    "    \n",
    "    #Apply same transformation to new df to validate and check the new histogram\n",
    "    wine_skewed_df[column], lambda_boxcox = boxcox(column_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287474e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns in the DataFrame\n",
    "columns_to_plot = wine_skewed_df.columns\n",
    "\n",
    "# Create a figure with multiple rows and two columns per row\n",
    "num_rows = len(columns_to_plot)\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, 2*num_rows))\n",
    "\n",
    "# Plot histograms for each column in wine_skewed_df and wine\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    sns.histplot(wine[column], ax=axes[i, 0], color=\"#FFC0CB\", bins=10)\n",
    "    sns.histplot(wine_skewed_df[column], ax=axes[i, 1], color=\"#87CEFA\", bins=10)\n",
    "\n",
    "    # Set titles for the histograms\n",
    "    axes[i, 0].set_title(f'{column} (Before Transformation)')\n",
    "    axes[i, 1].set_title(f'{column} (After Transformation)')\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44955ab1",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "wine_train, wine_test = train_test_split(wine, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2271d43",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in wine_skewed_df.columns:\n",
    "    wine_train[column], lambda_boxcox = boxcox(wine_train[column])\n",
    "    wine_test[column] = boxcox(wine_test[column],lambda_boxcox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddad40",
   "metadata": {},
   "source": [
    "Scale the Data\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d91a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "columns_to_scale = wine.drop(['quality' ,'Type'], axis=1).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(wine_train[columns_to_scale])\n",
    "\n",
    "wine_train[columns_to_scale] = scaler.transform(wine_train[columns_to_scale])\n",
    "wine_test[columns_to_scale] = scaler.transform(wine_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d5d7b",
   "metadata": {},
   "source": [
    "Create the Target\n",
    "-----------------------\n",
    "Wine quality of greater than 5 is a positive class and 5 or lower is the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train['target'] = 0.0\n",
    "wine_train['target'][wine_train['quality'] > 5] = 1.0\n",
    "wine_test['target'] = 0.0\n",
    "wine_test['target'][wine_test['quality'] > 5] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a73901",
   "metadata": {},
   "source": [
    "Logistic Regression Model Trial\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'target ~ 0 + Q(\"fixed acidity\") + Q(\"volatile acidity\")+ Q(\"citric acid\") + Q(\"residual sugar\") ' + \\\n",
    "           ' + chlorides + Q(\"free sulfur dioxide\") + Q(\"total sulfur dioxide\") + density + pH' + \\\n",
    "            '+ sulphates + alcohol + C(Type) '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7eda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, X_train = dmatrices(formula, wine_train, return_type='dataframe')\n",
    "y_train = Y_train['target'].values\n",
    "Y_test, X_test = dmatrices(formula, wine_test, return_type='dataframe')\n",
    "y_test = Y_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "result = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction_train = model.predict(X_train)\n",
    "print(metrics.accuracy_score(y_train, prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eeeaa5",
   "metadata": {},
   "source": [
    "Test Accuracy\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7280f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cc511",
   "metadata": {},
   "source": [
    "Check for Baseline Accuracy \n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343661ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train is 0 or 1.\n",
    "print('Number of positive examples =', len(y_train[y_train==1]))\n",
    "print('Number of negative examples =', len(y_train[y_train==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples_in_test = len(y_test[y_test==1])\n",
    "total_examples_in_test = len(y_test)\n",
    "\n",
    "print('Number of examples where baseline is correct =', positive_examples_in_test)\n",
    "print('Baseline accuracy =', positive_examples_in_test * 1.0 / total_examples_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb21e1",
   "metadata": {},
   "source": [
    "Our baseline accuracy is 61% but our Logisitic Test accuracy is 74.6%, but can we improve it? \n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48d577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = pd.Series(model.coef_[0],\n",
    "                 index=X_train.columns.values)\n",
    "weights.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813153c5",
   "metadata": {},
   "source": [
    "- Alcohol is the most important factor in determining the quality of the wine...make of that what you will\n",
    "- Volatile Acidity has the lowest weightage, indicating a decline of quality as volatility increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea2ab7",
   "metadata": {},
   "source": [
    "Decision Tree Classifier\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model2 = tree.DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69d6ce",
   "metadata": {},
   "source": [
    "Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_train = model2.predict(X_train)\n",
    "print(metrics.accuracy_score(y_train, prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6298e",
   "metadata": {},
   "source": [
    "Test Accuracy \n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict(X_test)\n",
    "print(round(metrics.accuracy_score(y_test, prediction),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f082f",
   "metadata": {},
   "source": [
    "Huge drop off in accuracy, clearly we can do better when it comes to a decision tree but will the best version be better than a logistic regression?\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2e9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the folds in the training data\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "decision_tree_tracking_df=pd.DataFrame(columns=[\"Tree Depth\",\"Accuracy Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over max_depth\n",
    "for max_depth in range(2,6):\n",
    "    #Run Decision Tree for each node\n",
    "    model3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "    \n",
    "    #Calculate the cross val scores based on each fold\n",
    "    scores = cross_val_score(model3, X_train, y_train, cv=kfold)\n",
    "    \n",
    "    #Print the Depth and Avg Accuracy\n",
    "    print('Depth = {} Accuracy = {}'.format(max_depth, round(scores.mean(),3)))\n",
    "    \n",
    "    \n",
    "    #Append this to a Decision Tree DataFrame\n",
    "    new_row_df = pd.DataFrame([[max_depth,scores.mean()]], columns=decision_tree_tracking_df.columns)\n",
    "    decision_tree_tracking_df=decision_tree_tracking_df.append(new_row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f99fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResetIndex & Choose the Best Depth\n",
    "decision_tree_tracking_df.reset_index(drop=True,inplace=True)\n",
    "best_depth = decision_tree_tracking_df.iloc[decision_tree_tracking_df[\"Accuracy Score\"].idxmax()][\"Tree Depth\"]\n",
    "\n",
    "#Create Model on Best Depth\n",
    "model3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth= best_depth)\n",
    "\n",
    "#Train & Test\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "print(\"\\nDecision Trees Test Accuracy - \", round(metrics.accuracy_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00da111",
   "metadata": {},
   "source": [
    "The best performing accuracy is 73.8% which is slightly worse than our Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c6094",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to track the results\n",
    "bagging_tracking_df = pd.DataFrame(columns=[\"Tree Depth\", \"Number of Estimators\", \"Accuracy Score\"])\n",
    "\n",
    "#Run 2 For Loops, one for each node and the other for number of trees\n",
    "for max_depth in [2,5,10]:\n",
    "    for n_estimators in [100, 500, 1000]:\n",
    "            base_estimator = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "\n",
    "            # Initialize Bagging Classifier with desired parameters\n",
    "            model_bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
    "\n",
    "            # Use cross-validation to evaluate the model\n",
    "            scores_bagging = cross_val_score(model_bagging, X_train, y_train, cv=kfold)\n",
    "\n",
    "            # Calculate and print the average score\n",
    "            print('Bagging - Depth = {} Trees = {} Accuracy = {}'.format(max_depth, n_estimators, round(scores_bagging.mean(),3)))\n",
    "            \n",
    "            #Append the depth, estimator and score to a dataframe column\n",
    "            new_row_df = pd.DataFrame([[max_depth, n_estimators, scores_bagging.mean()]], columns=bagging_tracking_df.columns)\n",
    "            bagging_tracking_df = bagging_tracking_df.append(new_row_df)\n",
    "\n",
    "#Add to file BaggingBestParam\n",
    "bagging_tracking_df.to_csv(\"BaggingBestParam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec32380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We convert the BestParam csv into a df and reset index\n",
    "bagging_tracking_df=pd.read_csv(\"BaggingBestParam.csv\")\n",
    "bagging_tracking_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Pull the best Depth and Trees based on the Accuracy Score\n",
    "best_depth=int(bagging_tracking_df.iloc[bagging_tracking_df[\"Accuracy Score\"].idxmax()][\"Tree Depth\"])\n",
    "best_n=int(bagging_tracking_df.iloc[bagging_tracking_df[\"Accuracy Score\"].idxmax()][\"Number of Estimators\"])\n",
    "\n",
    "\n",
    "print('Bagging Classifier best parameters after CV - Depth = {} Trees = {}'.format(best_depth, best_n))\n",
    "\n",
    "#Create the Base Model\n",
    "base_estimator = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth)\n",
    "\n",
    "# Initialize Bagging Classifier with desired parameters\n",
    "model_bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=best_n)\n",
    "\n",
    "\n",
    "#Fit the model and make prediction on test set\n",
    "model_bagging.fit(X_train, y_train)\n",
    "y_pred = model_bagging.predict(X_test)\n",
    "\n",
    "print(\"Bagging Classifier Test Accuracy - \",round(metrics.accuracy_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ceeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get averaged feature importances from all base estimators\n",
    "if hasattr(model_bagging, 'estimators_features_'):\n",
    "    feature_importances = np.array(model_bagging.estimators_features_).mean(axis=0)\n",
    "else:\n",
    "    raise ValueError(\"BaggingClassifier does not have averaged feature importances.\")\n",
    "\n",
    "# Create a DataFrame to hold feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color = \"skyblue\")\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Top Features Importance from BaggingClassifier')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5f44b",
   "metadata": {},
   "source": [
    "## Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Tracking DF\n",
    "RF_tracking_df=pd.DataFrame(columns=[\"Tree Depth\",\"Number of Trees\",\"Max Features\",\"Accuracy Score\"])\n",
    "\n",
    "#For Loop of Nodes, For Loop of Trees, and Mtry\n",
    "for max_depth in [2,5,10]:\n",
    "    for n_estimators in [100,500,1000]:\n",
    "        for mtry in [\"sqrt\",5]:\n",
    "        # Initialize Random Forest Classifier with desired parameters\n",
    "            model_rf = RandomForestClassifier(n_estimators=n_estimators, criterion='entropy', max_depth=max_depth,max_features=mtry)\n",
    "\n",
    "            # Use cross-validation to evaluate the model\n",
    "            scores_rf = cross_val_score(model_rf, X_train, y_train, cv=kfold)\n",
    "\n",
    "            # Calculate and print the average score\n",
    "            print('Random Forest - Depth = {} Trees = {} Mtry = {} Accuracy = {}'.format(max_depth, n_estimators,mtry, round(scores_rf.mean(),3)))\n",
    "            \n",
    "            #Append to RandomForest DataFrame \n",
    "            new_row_df = pd.DataFrame([[max_depth,n_estimators,mtry,scores_rf.mean()]], columns=RF_tracking_df.columns)\n",
    "            RF_tracking_df=RF_tracking_df.append(new_row_df)\n",
    "            \n",
    "RF_tracking_df.to_csv(\"RFBestParam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DF and reset index\n",
    "RF_tracking_df=pd.read_csv(\"RFBestParam.csv\")\n",
    "RF_tracking_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Pull the best node and tree for training accuracy\n",
    "best_depth=RF_tracking_df.iloc[RF_tracking_df[\"Accuracy Score\"].idxmax()][\"Tree Depth\"]\n",
    "best_n=RF_tracking_df.iloc[RF_tracking_df[\"Accuracy Score\"].idxmax()][\"Number of Trees\"]\n",
    "\n",
    "#Pull best Mtry\n",
    "try:\n",
    "    best_feat=int(RF_tracking_df.iloc[RF_tracking_df[\"Accuracy Score\"].idxmax()][\"Max Features\"])\n",
    "except:\n",
    "    best_feat=RF_tracking_df.iloc[RF_tracking_df[\"Accuracy Score\"].idxmax()][\"Max Features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524443ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the results\n",
    "print('Random Forest best parameters after CV - Depth = {} Trees = {} Mtry = {}'.format(best_depth, best_n,best_feat))\n",
    "\n",
    "#Create the new model with the best features\n",
    "model_rf = RandomForestClassifier(n_estimators=int(best_n), criterion='entropy',\\\n",
    " max_depth=int(best_depth),max_features=best_feat)\n",
    "\n",
    "#Fit the model and predict\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Test Accuracy - \", round(metrics.accuracy_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"feature_importances\": sorted_importances,\n",
    "    \"column_names\": sorted_column_names\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances from the fitted model\n",
    "feature_importances = model_rf.feature_importances_\n",
    "\n",
    "# Get the column names of the most important features\n",
    "column_names = X_train.columns[np.argsort(feature_importances)[::-1]]\n",
    "\n",
    "data = {\n",
    "    \"feature_importances\": feature_importances,\n",
    "    \"column_names\": sorted_column_names\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(\"feature_importances\",inplace=True)\n",
    "\n",
    "# Plot the feature importances in descending order with sorted column names\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(df[\"feature_importances\"])), df[\"feature_importances\"], tick_label=df[\"column_names\"], color=\"skyblue\")\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances in Random Forest Predictor')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291c6bc",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boost_tracking_df=pd.DataFrame(columns=[\"Tree Depth\",\"Number of Trees\",\"Shrinkage\",\"Accuracy Score\"])\n",
    "\n",
    "#For loop depth, for loop trees, for loop for shrinkage\n",
    "for max_depth in [2,5,10]:\n",
    "    for n_estimators in [100, 500,1000]:\n",
    "        for shrinkage in [0.1,0.2]:\n",
    "        # Initialize Random Forest Classifier with desired parameters\n",
    "            model_boost = GradientBoostingClassifier(max_depth=max_depth,n_estimators=n_estimators,\\\n",
    "                                                     learning_rate=shrinkage)\n",
    "            # Use cross-validation to evaluate the model\n",
    "            scores_boost = cross_val_score(model_boost, X_train, y_train, cv=kfold)\n",
    "\n",
    "            # Calculate and print the average score\n",
    "            print('Boosting - Depth = {} Trees = {} Shrinkage = {} Accuracy = {}'.format(max_depth, n_estimators,shrinkage, round(scores_boost.mean(),3)))\n",
    "            \n",
    "            #Append to Boost Tree Dataframe\n",
    "            new_row_df = pd.DataFrame([[max_depth,n_estimators,shrinkage,scores_boost.mean()]], columns=Boost_tracking_df.columns)\n",
    "            Boost_tracking_df=Boost_tracking_df.append(new_row_df)\n",
    "\n",
    "Boost_tracking_df.to_csv(\"BoostBestParam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287167d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df and reset index\n",
    "Boost_tracking_df=pd.read_csv(\"BoostBestParam.csv\")\n",
    "Boost_tracking_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Pull best depth, trees and shirnkage parameter\n",
    "best_depth=Boost_tracking_df.iloc[Boost_tracking_df[\"Accuracy Score\"].idxmax()][\"Tree Depth\"]\n",
    "best_n=Boost_tracking_df.iloc[Boost_tracking_df[\"Accuracy Score\"].idxmax()][\"Number of Trees\"]\n",
    "best_shrink=Boost_tracking_df.iloc[Boost_tracking_df[\"Accuracy Score\"].idxmax()][\"Shrinkage\"]\n",
    "\n",
    "print('Boosting best parameters - Depth = {} Trees = {} Shrinkage = {}'.format(best_depth, best_n,best_shrink))\n",
    "\n",
    "#Use best features for the model\n",
    "model_boost = GradientBoostingClassifier(max_depth=int(best_depth),n_estimators=int(best_n),\\\n",
    "                                             learning_rate=best_shrink)\n",
    "#Fit result\n",
    "model_boost.fit(X_train, y_train)\n",
    "y_pred = model_boost.predict(X_test)\n",
    "\n",
    "print(\"Boosting Test Accuracy - \", round(metrics.accuracy_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b49afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the feature importances from the fitted model\n",
    "feature_importances = model_boost.feature_importances_\n",
    "\n",
    "# Get the column names of the most important features\n",
    "column_names = X_train.columns[np.argsort(feature_importances)]\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "sorted_importances = np.sort(feature_importances)[::-1]\n",
    "\n",
    "# Plot the feature importances in descending order with column names\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_importances)), sorted_importances, tick_label=column_names, color = \"skyblue\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances in Gradient Boosting Classifier')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b572c",
   "metadata": {},
   "source": [
    "Neural Network\n",
    "------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c7535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Neural_tracking_df = pd.DataFrame(columns=[\"Hidden Layer Size\", \"Learning Rate\", \"Epochs\", \"Accuracy Score\"])\n",
    "\n",
    "# Convert X and y to tensors\n",
    "x_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train.astype(int), dtype=torch.long)\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for size in [2, 4, 8, 16, 32, 64, 128]:\n",
    "    for lr in [0.1, 0.01, 0.001]:\n",
    "        for epochs in [50, 100, 150, 200, 500]:\n",
    "            # Initialize lists to store accuracy for each fold\n",
    "            fold_accuracies = []\n",
    "            \n",
    "            for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "                # Split the data into train and test sets for the current fold\n",
    "                x_train_fold = x_tensor[train_index]\n",
    "                y_train_fold = y_tensor[train_index]\n",
    "                x_test_fold = x_tensor[test_index]\n",
    "                y_test_fold = y_tensor[test_index]\n",
    "                \n",
    "                class ClassifierNN(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(ClassifierNN, self).__init__()\n",
    "                        self.layer1 = nn.Linear(13, size)  # Adjusted input size to 13\n",
    "                        self.layer2 = nn.ReLU()\n",
    "                        self.layer3 = nn.Linear(size, size) \n",
    "                        self.layer4 = nn.ReLU()\n",
    "                        self.layer5 = nn.Linear(size, 2)\n",
    "\n",
    "                    def forward(self, x):\n",
    "                        x = self.layer1(x)\n",
    "                        x = self.layer2(x)\n",
    "                        x = self.layer3(x)\n",
    "                        x = self.layer4(x)\n",
    "                        x = self.layer5(x)\n",
    "                        return x\n",
    "                \n",
    "                # Create the model and optimizer for each fold\n",
    "                model = ClassifierNN()\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                # Training\n",
    "                for epoch in range(epochs):\n",
    "                    optimizer.zero_grad()\n",
    "                    predictions = model(x_train_fold)\n",
    "                    loss = criterion(predictions, y_train_fold)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Evaluate the model on the current fold using the training data\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_predictions = model(x_test_fold)\n",
    "\n",
    "                _, y_pred_test = torch.max(test_predictions, 1)\n",
    "                correct = (y_pred_test == y_test_fold).sum().item()\n",
    "                total = y_test_fold.size(0)\n",
    "                accuracy = correct / total\n",
    "                \n",
    "                fold_accuracies.append(accuracy)\n",
    "\n",
    "                print('Fold {}/{} - Hidden Layer Size = {}, Learning rate = {}, Epochs = {}, Accuracy = {}'.format(fold + 1, k_folds, size, lr, epochs, round(accuracy,3)))\n",
    "            \n",
    "            # Calculate the average accuracy across all folds\n",
    "            avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "\n",
    "            new_row_df = pd.DataFrame([[size, lr, epochs, avg_accuracy]], columns=Neural_tracking_df.columns)\n",
    "            Neural_tracking_df = Neural_tracking_df.append(new_row_df)\n",
    "Neural_tracking_df.to_csv(\"NNBestParam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural_tracking_df=pd.read_csv(\"NNBestParam.csv\")\n",
    "Neural_tracking_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "best_lr=float(Neural_tracking_df.iloc[Neural_tracking_df[\"Accuracy Score\"].idxmax()][\"Learning Rate\"])\n",
    "best_layer_size=int(Neural_tracking_df.iloc[Neural_tracking_df[\"Accuracy Score\"].idxmax()][\"Hidden Layer Size\"])\n",
    "best_epochs=int(Neural_tracking_df.iloc[Neural_tracking_df[\"Accuracy Score\"].idxmax()][\"Epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(13, best_layer_size)  # Adjusted input size to 13\n",
    "        self.layer2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(best_layer_size, best_layer_size)  # Output size of layer2 is 64\n",
    "        self.layer4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(best_layer_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "model = ClassifierNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
    "\n",
    "# Training\n",
    "epochs = best_epochs\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(x_tensor)\n",
    "    loss = criterion(predictions, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model on the current fold using the training data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(torch.tensor(X_test.to_numpy(), dtype=torch.float32))\n",
    "\n",
    "_, y_pred_test = torch.max(test_predictions, 1)\n",
    "correct = (y_pred_test == torch.tensor(y_test, dtype=torch.long)).sum().item()  # Convert y_test to a tensor\n",
    "total = y_test.size\n",
    "accuracy = correct / total\n",
    "\n",
    "print('NN Best parameters - Hidden Layer Size={}, Learning rate={}, Epochs={}, Accuracy Score={}'.format( best_layer_size, best_lr, best_epochs, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
